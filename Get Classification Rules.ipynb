{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["IF outlook == 'Overcast' \n","\tTHEN play = 'Yes'\n","IF outlook == 'Rain' AND wind == 'Strong' \n","\tTHEN play = 'No'\n","IF outlook == 'Rain' AND wind == 'Weak' \n","\tTHEN play = 'Yes'\n","IF outlook == 'Sunny' AND humidity == 'High' \n","\tTHEN play = 'No'\n","IF outlook == 'Sunny' AND humidity == 'Normal' \n","\tTHEN play = 'Yes'\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","# Define the entropy and information gain functions\n","def find_entropy(df):\n","    # Target column\n","    target = df.keys()[-1]\n","    entropy = 0\n","    values = df[target].unique()\n","    # Calculate entropy\n","    for value in values:\n","        fraction = df[target].value_counts()[value] / len(df[target])\n","        entropy += -fraction * np.log2(fraction)\n","    return entropy\n","\n","def average_information(df, attribute):\n","    target = df.keys()[-1]   # Target column\n","    target_variables = df[target].unique()\n","    variables = df[attribute].unique()\n","    entropy2 = 0\n","    for variable in variables:\n","        entropy = 0\n","        for target_variable in target_variables:\n","            num = len(df[attribute][df[attribute] == variable][df[target] == target_variable])\n","            den = len(df[attribute][df[attribute] == variable])\n","            fraction = num / (den + 1e-9)\n","            entropy += -fraction * np.log2(fraction + 1e-9)\n","        fraction2 = den / len(df)\n","        entropy2 += -fraction2 * entropy\n","    return abs(entropy2)\n","\n","def find_winner(df):\n","    IG = []\n","    for key in df.keys()[:-1]:\n","        IG.append(find_entropy(df) - average_information(df, key))\n","    return df.keys()[:-1][np.argmax(IG)]\n","\n","def get_subtable(df, node, value):\n","    return df[df[node] == value].reset_index(drop=True)\n","\n","def build_tree(df, tree=None):\n","    target = df.keys()[-1]\n","\n","    node = find_winner(df)\n","    attValue = np.unique(df[node])\n","\n","    if tree is None:\n","        tree = {}\n","        tree[node] = {}\n","\n","    for value in attValue:\n","        subtable = get_subtable(df, node, value)\n","        clValue, counts = np.unique(subtable[target], return_counts=True)\n","\n","        if len(counts) == 1:\n","            tree[node][value] = clValue[0]\n","        else:\n","            tree[node][value] = build_tree(subtable)\n","\n","    return tree\n","\n","# Load the dataset from the URL and remove the 'day' column\n","url = \"https://raw.githubusercontent.com/Keipatr/Classification-Rules/main/play_tennis.csv\"\n","df = pd.read_csv(url)\n","df = df.drop('day', axis=1)\n","\n","# Build the decision tree\n","tree = build_tree(df)\n","\n","# Function to print classification rules\n","def print_classification_rules(tree, parent_rule=\"IF\", indent=\"  \", class_label=None):\n","    rules = []\n","\n","    for attribute, values in tree.items():\n","        for value, sub_tree in values.items():\n","            new_rule = f\"{parent_rule} {attribute} == '{value}'\"\n","            if isinstance(sub_tree, dict):\n","                rules.extend(print_classification_rules(sub_tree, new_rule + \" AND\", indent, class_label))\n","            else:\n","                if class_label is not None:\n","                    rules.append(f\"{new_rule} \\n\\tTHEN {class_label} = '{sub_tree}'\")\n","\n","    return rules\n","\n","# Specify the class label based on the last column (target)\n","class_label = df.keys()[-1]\n","\n","# Usage: Get and print the classification rules\n","rules = print_classification_rules(tree, class_label=class_label)\n","for rule in rules:\n","    print(rule)\n"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["IF Warm-blooded == '0' AND Has Legs == '0' AND Aquatic Creature == '0' \n","\tTHEN Class = 'reptiles'\n","IF Warm-blooded == '0' AND Has Legs == '0' AND Aquatic Creature == '1' \n","\tTHEN Class = 'fishes'\n","IF Warm-blooded == '0' AND Has Legs == '1' AND Hibernates == '0' \n","\tTHEN Class = 'reptiles'\n","IF Warm-blooded == '0' AND Has Legs == '1' AND Hibernates == '1' \n","\tTHEN Class = 'amphibians'\n","IF Warm-blooded == '1' AND Gives Birth == '0' \n","\tTHEN Class = 'birds'\n","IF Warm-blooded == '1' AND Gives Birth == '1' \n","\tTHEN Class = 'mammals'\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","# Define the entropy and information gain functions\n","def find_entropy(df):\n","    # Target column\n","    target = df.keys()[-1]\n","    entropy = 0\n","    values = df[target].unique()\n","    # Calculate entropy\n","    for value in values:\n","        fraction = df[target].value_counts()[value] / len(df[target])\n","        entropy += -fraction * np.log2(fraction)\n","    return entropy\n","\n","def average_information(df, attribute):\n","    target = df.keys()[-1]   # Target column\n","    target_variables = df[target].unique()\n","    variables = df[attribute].unique()\n","    entropy2 = 0\n","    for variable in variables:\n","        entropy = 0\n","        for target_variable in target_variables:\n","            num = len(df[attribute][df[attribute] == variable][df[target] == target_variable])\n","            den = len(df[attribute][df[attribute] == variable])\n","            fraction = num / (den + 1e-9)\n","            entropy += -fraction * np.log2(fraction + 1e-9)\n","        fraction2 = den / len(df)\n","        entropy2 += -fraction2 * entropy\n","    return abs(entropy2)\n","\n","def find_winner(df):\n","    IG = []\n","    for key in df.keys()[:-1]:\n","        IG.append(find_entropy(df) - average_information(df, key))\n","    return df.keys()[:-1][np.argmax(IG)]\n","\n","def get_subtable(df, node, value):\n","    return df[df[node] == value].reset_index(drop=True)\n","\n","def build_tree(df, tree=None):\n","    target = df.keys()[-1]\n","\n","    node = find_winner(df)\n","    attValue = np.unique(df[node])\n","\n","    if tree is None:\n","        tree = {}\n","        tree[node] = {}\n","\n","    for value in attValue:\n","        subtable = get_subtable(df, node, value)\n","        clValue, counts = np.unique(subtable[target], return_counts=True)\n","\n","        if len(counts) == 1:\n","            tree[node][value] = clValue[0]\n","        else:\n","            tree[node][value] = build_tree(subtable)\n","\n","    return tree\n","\n","# Load the dataset from the URL\n","url = \"https://raw.githubusercontent.com/Keipatr/Classification-Rules/main/vertebrate.csv\"\n","df = pd.read_csv(url)\n","df = df.drop('Name',axis=1)\n","\n","\n","# Build the decision tree\n","tree = build_tree(df)\n","\n","# Function to print classification rules\n","def print_classification_rules(tree, parent_rule=\"IF\", indent=\"  \", class_label=None):\n","    rules = []\n","\n","    for attribute, values in tree.items():\n","        for value, sub_tree in values.items():\n","            new_rule = f\"{parent_rule} {attribute} == '{value}'\"\n","            if isinstance(sub_tree, dict):\n","                rules.extend(print_classification_rules(sub_tree, new_rule + \" AND\", indent, class_label))\n","            else:\n","                if class_label is not None:\n","                    rules.append(f\"{new_rule} \\n\\tTHEN {class_label} = '{sub_tree}'\")\n","\n","    return rules\n","\n","# Specify the class label based on the last column (target)\n","class_label = df.keys()[-1]\n","\n","# Usage: Get and print the classification rules\n","rules = print_classification_rules(tree, class_label=class_label)\n","for rule in rules:\n","    print(rule)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["IF odor == 'a' \n","\tTHEN class = 'e'\n","IF odor == 'c' \n","\tTHEN class = 'p'\n","IF odor == 'f' \n","\tTHEN class = 'p'\n","IF odor == 'l' \n","\tTHEN class = 'e'\n","IF odor == 'm' \n","\tTHEN class = 'p'\n","IF odor == 'n' AND spore-print-color == 'b' \n","\tTHEN class = 'e'\n","IF odor == 'n' AND spore-print-color == 'h' \n","\tTHEN class = 'e'\n","IF odor == 'n' AND spore-print-color == 'k' \n","\tTHEN class = 'e'\n","IF odor == 'n' AND spore-print-color == 'n' \n","\tTHEN class = 'e'\n","IF odor == 'n' AND spore-print-color == 'o' \n","\tTHEN class = 'e'\n","IF odor == 'n' AND spore-print-color == 'r' \n","\tTHEN class = 'p'\n","IF odor == 'n' AND spore-print-color == 'w' AND habitat == 'd' AND gill-size == 'b' \n","\tTHEN class = 'e'\n","IF odor == 'n' AND spore-print-color == 'w' AND habitat == 'd' AND gill-size == 'n' \n","\tTHEN class = 'p'\n","IF odor == 'n' AND spore-print-color == 'w' AND habitat == 'g' \n","\tTHEN class = 'e'\n","IF odor == 'n' AND spore-print-color == 'w' AND habitat == 'l' AND cap-color == 'c' \n","\tTHEN class = 'e'\n","IF odor == 'n' AND spore-print-color == 'w' AND habitat == 'l' AND cap-color == 'n' \n","\tTHEN class = 'e'\n","IF odor == 'n' AND spore-print-color == 'w' AND habitat == 'l' AND cap-color == 'w' \n","\tTHEN class = 'p'\n","IF odor == 'n' AND spore-print-color == 'w' AND habitat == 'l' AND cap-color == 'y' \n","\tTHEN class = 'p'\n","IF odor == 'n' AND spore-print-color == 'w' AND habitat == 'p' \n","\tTHEN class = 'e'\n","IF odor == 'n' AND spore-print-color == 'w' AND habitat == 'w' \n","\tTHEN class = 'e'\n","IF odor == 'n' AND spore-print-color == 'y' \n","\tTHEN class = 'e'\n","IF odor == 'p' \n","\tTHEN class = 'p'\n","IF odor == 's' \n","\tTHEN class = 'p'\n","IF odor == 'y' \n","\tTHEN class = 'p'\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","# Define the entropy and information gain functions\n","def find_entropy(df):\n","    # Target column\n","    target = df.keys()[-1]\n","    entropy = 0\n","    values = df[target].unique()\n","    # Calculate entropy\n","    for value in values:\n","        fraction = df[target].value_counts()[value] / len(df[target])\n","        entropy += -fraction * np.log2(fraction)\n","    return entropy\n","\n","def average_information(df, attribute):\n","    target = df.keys()[-1]   # Target column\n","    target_variables = df[target].unique()\n","    variables = df[attribute].unique()\n","    entropy2 = 0\n","    for variable in variables:\n","        entropy = 0\n","        for target_variable in target_variables:\n","            num = len(df[attribute][df[attribute] == variable][df[target] == target_variable])\n","            den = len(df[attribute][df[attribute] == variable])\n","            fraction = num / (den + 1e-9)\n","            entropy += -fraction * np.log2(fraction + 1e-9)\n","        fraction2 = den / len(df)\n","        entropy2 += -fraction2 * entropy\n","    return abs(entropy2)\n","\n","def find_winner(df):\n","    IG = []\n","    for key in df.keys()[:-1]:\n","        IG.append(find_entropy(df) - average_information(df, key))\n","    return df.keys()[:-1][np.argmax(IG)]\n","\n","def get_subtable(df, node, value):\n","    return df[df[node] == value].reset_index(drop=True)\n","\n","def build_tree(df, depth, max_depth, tree=None):\n","    target = df.keys()[-1]\n","\n","    if depth >= max_depth:\n","        return None\n","\n","    node = find_winner(df)\n","    attValue = np.unique(df[node])\n","\n","    if tree is None:\n","        tree = {}\n","        tree[node] = {}\n","\n","    for value in attValue:\n","        subtable = get_subtable(df, node, value)\n","        clValue, counts = np.unique(subtable[target], return_counts=True)\n","\n","        if len(counts) == 1:\n","            tree[node][value] = clValue[0]\n","        else:\n","            subtree = build_tree(subtable, depth + 1, max_depth)\n","            if subtree:\n","                tree[node][value] = subtree\n","\n","    return tree\n","\n","# Load the dataset from the URL\n","url = \"https://raw.githubusercontent.com/Keipatr/Mushroom-Classification/main/mushrooms.csv\"\n","df = pd.read_csv(url)\n","df = df[[col for col in df.columns if col != \"class\"] + [\"class\"]]\n","\n","# Specify the maximum depth for the decision tree\n","max_depth = 100\n","\n","# Build the decision tree\n","tree = build_tree(df, 0, max_depth)\n","\n","# Function to print classification rules\n","def print_classification_rules(tree, parent_rule=\"IF\", indent=\"  \", class_label=None):\n","    rules = []\n","\n","    for attribute, values in tree.items():\n","        for value, sub_tree in values.items():\n","            new_rule = f\"{parent_rule} {attribute} == '{value}'\"\n","            if isinstance(sub_tree, dict):\n","                rules.extend(print_classification_rules(sub_tree, new_rule + \" AND\", indent, class_label))\n","            else:\n","                if class_label is not None:\n","                    rules.append(f\"{new_rule} \\n\\tTHEN {class_label} = '{sub_tree}'\")\n","\n","    return rules\n","\n","# Specify the class label based on the last column (target)\n","class_label = df.keys()[-1]\n","\n","# Usage: Get and print the classification rules\n","rules = print_classification_rules(tree, class_label=class_label)\n","for rule in rules:\n","    print(rule)"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":2}
